{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os,sys\n",
    "from sklearn import model_selection\n",
    "from sklearn import datasets\n",
    "import re,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words in common.\n",
    "stop_word=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is a list further made in form of tuple , where first element is name of document and second is the text in documents.\n",
    "#Y is the category\n",
    "X  =[] \n",
    "Y = []\n",
    "for category in os.listdir(\"/Users/neelamagarwal/desktop/Naive Bayes/20_newsgroups\"):\n",
    "    for document in os.listdir(\"/Users/neelamagarwal/desktop/Naive Bayes/20_newsgroups/\"+category):\n",
    "        with open(\"/Users/neelamagarwal/desktop/Naive Bayes/20_newsgroups/\"+category+'/'+document, \"r\",encoding = \"utf-8\",errors = \"ignore\") as f:\n",
    "            X.append((document,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data in training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(X,Y,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Dictionary of words with their corresponding frequency\n",
    "dic={}\n",
    "for i in range(len(x_train)):\n",
    "    #Took [1] because [0] is name of doc and [1] is text in doc\n",
    "    word=x_train[i][1].lower()\n",
    "    #splitting the text into words\n",
    "    stripped=re.split(r'\\W+',word)\n",
    "    #Iterating over each word\n",
    "    for s in stripped:\n",
    "        #we will not include stop_words, alpha-numerics, punctuations or irrelevant word of length less than 2 in our dictionary\n",
    "        if not(s.isalpha()) or s in stop_word or len(s)<=2:\n",
    "            continue\n",
    "        if s in dic:\n",
    "            dic[s]+=1\n",
    "        else:\n",
    "            dic[s]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the dictionary on basis of frequency of words in descending order\n",
    "sorted_dic = sorted(dic.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking top 2000 words with max freuqency as our feature\n",
    "features=[sorted_dic[i][0] for i in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_train dataset\n",
    "#No. of rows is equivalent to rows in x_train, and column is equal to length of features\n",
    "x_train_dataset=np.zeros([len(x_train),len(features)],int)\n",
    "for i in range(len(x_train)):\n",
    "    words=x_train[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our feature list\n",
    "        if j in features:\n",
    "            x_train_dataset[i][features.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_test dataset\n",
    "#No. of rows is equivalent to rows in x_test, and column is equal to length of feature list\n",
    "x_test_dataset=np.zeros([len(x_test),len(features)],int)\n",
    "for i in range(len(x_test)):\n",
    "    words=x_test[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our feature list\n",
    "        if j in features:\n",
    "            x_test_dataset[i][features.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our Dataset is ready\n",
    "# we will create model for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dictionary for implementing Naive Baye's\n",
    "def fit(x_train_dataset,y_train):\n",
    "    count={}\n",
    "    total_word=0\n",
    "    y_train=np.array(y_train)\n",
    "    #Total no. of document is calculated\n",
    "    count[\"total_doc\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for i in classes:\n",
    "        temp=0\n",
    "        #selecting x_train corresponding to class present in y_train\n",
    "        x_train_with_i=x_train_dataset[y_train==i]\n",
    "        #finding length of data with category corresponding to i \n",
    "        temp2=x_train_with_i.shape[0]\n",
    "        count[i]={}\n",
    "        #Iterating over answer1(actual feature list)\n",
    "        for feature in features:\n",
    "            #Calculating total word in feature\n",
    "            l=(x_train_with_i[:,features.index(feature)]).sum()\n",
    "            count[i][feature]=l\n",
    "            temp+=l\n",
    "        #Total word in that class\n",
    "        count[i][\"word_in_class\"]=temp\n",
    "        #Length of data with y_train belonging to specific class\n",
    "        count[i][\"length\"]=temp2\n",
    "        \n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x_test,dic,classes):\n",
    "    prob=np.log(dic[classes][\"length\"])-np.log(dic[\"total_doc\"])\n",
    "    feature=list(dic[classes].keys())\n",
    "    #-2 is done becuase there will be \"length\" and \"word in class\" present in feature. \n",
    "    for j in range (len(feature)-2):\n",
    "        xj=x_test[j]\n",
    "        #If frequency is 0, we will not consider it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #Extra addition part is Laplace correction\n",
    "            num=dic[classes][feature[j]]+1\n",
    "            den=dic[classes][\"word_in_class\"]+len(dic[classes].keys())-2\n",
    "            current_prob=np.log(num)-np.log(den)\n",
    "        prob+=current_prob\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best_class or probable answer will be returned from here\n",
    "def predict_for_single(x_test,dic):\n",
    "    first_run=True\n",
    "    classes=dic.keys()\n",
    "    for i in classes:\n",
    "        if i==\"total_doc\":\n",
    "            continue\n",
    "        prob=probability(x_test,dic,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            first_run=False\n",
    "            best_class=i\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,dic):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predict_for_single(x,dic))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test,y_pred):\n",
    "        count = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_test[i]:\n",
    "                count+=1\n",
    "        return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we find prediction by inbuilt Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(x_train_dataset,y_train)\n",
    "y_pred_inbuilt = clf1.predict(x_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on testing data: 0.8554\n",
      "[[202   0   0   0   0   0   2   0   3   0   0   1   1   0   1   2   0   1\n",
      "    0  47]\n",
      " [  0 170  12  18  12   7  12   4   0   0   0   0   2   1   1   0   0   0\n",
      "    0   0]\n",
      " [  0   3 212  23   6  11   9   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   5   6 180  38   0   5   1   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  21 225   0   5   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  17  31   5   4 181   2   0   3   0   1   0   2   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   2   2   0 217   3   1   0   0   0   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   2   0  10 225   7   0   1   0   1   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   7   5 233   1   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   3   3   5 244  11   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   2   3   1  12 234   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   4   0   0   0   1   1   0   0   0   0 210   3   1   1   0   0   0\n",
      "    1   0]\n",
      " [  0   4   0   4   3   0   6   5   0   0   0   1 213   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   4   0   1   3   2   2   2   1   1   0   1   9 260   5   0   0   0\n",
      "    1   1]\n",
      " [  0   4   0   0   0   0   1   2   0   3   0   0   4   0 239   0   1   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 256   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   1   4   1   0   0   0   0   1   0 216   0\n",
      "    8   3]\n",
      " [  0   1   0   0   0   0   2   1   3   0   0   0   0   0   0   0   3 232\n",
      "   17   2]\n",
      " [  0   0   0   0   0   0   2   0   2   2   1   3   0   0   1   1  30   7\n",
      "  174  22]\n",
      " [ 51   0   0   0   0   0   0   1   0   0   0   0   0   0   1  13  11   1\n",
      "   20 154]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.78      0.79       260\n",
      "           comp.graphics       0.80      0.71      0.75       239\n",
      " comp.os.ms-windows.misc       0.81      0.80      0.81       265\n",
      "comp.sys.ibm.pc.hardware       0.71      0.76      0.73       236\n",
      "   comp.sys.mac.hardware       0.76      0.89      0.82       253\n",
      "          comp.windows.x       0.90      0.73      0.80       248\n",
      "            misc.forsale       0.75      0.95      0.84       228\n",
      "               rec.autos       0.88      0.91      0.89       248\n",
      "         rec.motorcycles       0.88      0.94      0.91       247\n",
      "      rec.sport.baseball       0.92      0.92      0.92       266\n",
      "        rec.sport.hockey       0.94      0.93      0.94       252\n",
      "               sci.crypt       0.97      0.94      0.96       223\n",
      "         sci.electronics       0.88      0.89      0.89       238\n",
      "                 sci.med       0.99      0.89      0.94       293\n",
      "               sci.space       0.94      0.94      0.94       255\n",
      "  soc.religion.christian       0.94      1.00      0.97       256\n",
      "      talk.politics.guns       0.82      0.92      0.87       235\n",
      "   talk.politics.mideast       0.96      0.89      0.92       261\n",
      "      talk.politics.misc       0.78      0.71      0.75       245\n",
      "      talk.religion.misc       0.67      0.61      0.64       252\n",
      "\n",
      "               micro avg       0.86      0.86      0.86      5000\n",
      "               macro avg       0.86      0.86      0.85      5000\n",
      "            weighted avg       0.86      0.86      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#results of inbuilt naive bayes model\n",
    "print(\"Score on testing data:\",clf1.score(x_test_dataset,y_test))\n",
    "print(confusion_matrix(y_test,y_pred_inbuilt))\n",
    "print(classification_report(y_test,y_pred_inbuilt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now prediction by our model\n",
    "dictionary = fit(x_train_dataset,y_train)\n",
    "y_pred_self = predict(x_test_dataset,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on testing data: 0.8742\n",
      "[[220   0   0   0   0   0   0   0   1   0   0   1   0   1   1   0   0   1\n",
      "    0  35]\n",
      " [  0 194   7  13   5   4  11   1   0   0   0   0   0   4   0   0   0   0\n",
      "    0   0]\n",
      " [  0   7 192  31   5  18   6   0   0   0   0   2   1   0   0   0   0   0\n",
      "    3   0]\n",
      " [  0   5   2 192  31   0   5   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0  12 236   0   2   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  20  25   4   1 193   2   0   1   0   0   0   1   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   2   1   0 214   5   0   0   0   0   6   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   2   0   9 231   2   0   0   0   2   0   0   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   5   3 239   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   1 256   8   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   3   1   0   5 243   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   1   0   0   0   0   1   0   0   0 210   6   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0   3   0   0   0   0   6   2   0   0   0   0 227   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0   0   0   1   1   1   2   0   1   0   6 273   1   0   0   0\n",
      "    2   0]\n",
      " [  0   9   0   0   0   0   1   0   1   1   0   0   8   2 232   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 256   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0 223   0\n",
      "    8   1]\n",
      " [  0   1   0   0   0   0   0   0   2   0   0   0   0   0   1   0   5 233\n",
      "   17   2]\n",
      " [  0   0   0   0   0   0   1   1   1   1   0   1   0   0   2   0  36   6\n",
      "  180  16]\n",
      " [ 64   0   0   0   0   0   2   0   0   0   0   1   0   0   0  10  18   0\n",
      "   30 127]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.85      0.81       260\n",
      "           comp.graphics       0.78      0.81      0.80       239\n",
      " comp.os.ms-windows.misc       0.85      0.72      0.78       265\n",
      "comp.sys.ibm.pc.hardware       0.76      0.81      0.78       236\n",
      "   comp.sys.mac.hardware       0.84      0.93      0.88       253\n",
      "          comp.windows.x       0.89      0.78      0.83       248\n",
      "            misc.forsale       0.80      0.94      0.86       228\n",
      "               rec.autos       0.94      0.93      0.94       248\n",
      "         rec.motorcycles       0.94      0.97      0.96       247\n",
      "      rec.sport.baseball       0.97      0.96      0.97       266\n",
      "        rec.sport.hockey       0.96      0.96      0.96       252\n",
      "               sci.crypt       0.98      0.94      0.96       223\n",
      "         sci.electronics       0.87      0.95      0.91       238\n",
      "                 sci.med       0.97      0.93      0.95       293\n",
      "               sci.space       0.98      0.91      0.94       255\n",
      "  soc.religion.christian       0.96      1.00      0.98       256\n",
      "      talk.politics.guns       0.79      0.95      0.86       235\n",
      "   talk.politics.mideast       0.97      0.89      0.93       261\n",
      "      talk.politics.misc       0.74      0.73      0.74       245\n",
      "      talk.religion.misc       0.70      0.50      0.59       252\n",
      "\n",
      "               micro avg       0.87      0.87      0.87      5000\n",
      "               macro avg       0.87      0.87      0.87      5000\n",
      "            weighted avg       0.88      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results of our model\n",
    "print(\"Score on testing data:\",score(y_test,y_pred_self))\n",
    "print(confusion_matrix(y_test,y_pred_self))\n",
    "print(classification_report(y_test,y_pred_self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So score by our model = 0.8742\n",
    "### score by inbuilt model = 0.8554\n",
    "\n",
    "# So Our model is doing pretty well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
