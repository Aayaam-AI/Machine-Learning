{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we are building a simple network which contain no hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking AND gate as example\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[0,0,0,1]]).T\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useing sigmoid function as activation function.\n",
    "def sig(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative of sigmoid function\n",
    "def derivativeSig(z):\n",
    "    return sig(z) * (1 - sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74303209]\n",
      " [0.50621246]]\n",
      "[0.38930704]\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights and bias\n",
    "# We should initialize them in range (-1,1)\n",
    "weights = 2*np.random.random((2,1)) - 1 # Corresponding to two features\n",
    "bias = 2*np.random.random(1) - 1 # Since a single output unit only 1 bias is required\n",
    "print(weights)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27823769],\n",
       "       [0.49568968],\n",
       "       [0.14528405],\n",
       "       [0.3023568 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = X # It is output from input layer and this goes in following layer\n",
    "output = sig(np.dot(output0,weights) + bias)\n",
    "output\n",
    "# So this is output corresponding to current weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will construct network for one hidden layer containing two units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use same data and only number of features and bias will change\n",
    "# For hidden layer\n",
    "wh = 2*np.random.random((2,2)) - 1\n",
    "bh = 2*np.random.random((1,2)) - 1\n",
    "# For output layer\n",
    "wo = 2*np.random.random((2,1)) - 1\n",
    "bo = 2*np.random.random((1,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40968374],\n",
       "       [0.40475565],\n",
       "       [0.4063181 ],\n",
       "       [0.4006677 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = X # It is output from input layer and this goes in following layer\n",
    "output_hidden = sig(np.dot(output0,wh) + bh)\n",
    "output = sig(np.dot(output_hidden,wo) + bo)\n",
    "output\n",
    "# So this is output corresponding to current weights with one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Backpropogation on network with no hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.60298672]\n",
      " [5.60298674]]\n",
      "[-8.49664105]\n",
      "[[2.04111288e-04]\n",
      " [5.24681464e-02]\n",
      " [5.24681451e-02]\n",
      " [9.37575087e-01]]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1 #learning rate\n",
    "for iter in range(10000):\n",
    "    output0 = X \n",
    "    output = sig(np.dot(output0,weights) + bias)\n",
    "\n",
    "    first_term = output - Y\n",
    "    input_for_last_layer = np.dot(output0,weights) + bias\n",
    "    second_term = derivativeSig(input_for_last_layer)\n",
    "    first_two = first_term * second_term\n",
    "\n",
    "    wt_changes = np.array([[0.0],[0.0]])\n",
    "    bias_change = 0.0\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            wt_changes[i][0] += first_two[j][0] * output0[j][i]\n",
    "        \n",
    "    for j in range(4):\n",
    "        bias_change += first_two[j][0] * 1\n",
    "    \n",
    "    weights = weights - lr * wt_changes\n",
    "    bias = bias - lr * bias_change\n",
    "\n",
    "output = sig(np.dot(X,weights) + bias)\n",
    "print(weights)\n",
    "print(bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.47955292]\n",
      " [5.47955291]]\n",
      "[-8.31202093]\n",
      "[[2.45487030e-04]\n",
      " [5.55946754e-02]\n",
      " [5.55946757e-02]\n",
      " [9.33831093e-01]]\n"
     ]
    }
   ],
   "source": [
    "# We can do above thing in shorter way\n",
    "lr = 0.1 #learning rate\n",
    "for iter in range(10000):\n",
    "    output0 = X \n",
    "    output = sig(np.dot(output0,weights) + bias)\n",
    "\n",
    "    first_term = output - Y\n",
    "    input_for_last_layer = np.dot(output0,weights) + bias\n",
    "    second_term = derivativeSig(input_for_last_layer)\n",
    "    first_two = first_term * second_term\n",
    "\n",
    "    wt_changes = np.dot(output0.T,first_two)\n",
    "    bias_change = np.sum(first_two)\n",
    "    weights = weights - lr * wt_changes\n",
    "    bias = bias - lr * bias_change\n",
    "\n",
    "output = sig(np.dot(X,weights) + bias)\n",
    "print(weights)\n",
    "print(bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So our output is similar to actual Y values in both cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
